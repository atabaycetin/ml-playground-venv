# -*- coding: utf-8 -*-
"""Lab02.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HblFsd3yksL0aWJpoYbzvBplFGgCERb8

# Lab 02: Training a Custom Model

**Objective of this lab**: training a small custom model on the Tiny-ImageNet dataset.

## Dataset preparation
"""

"""We need to adjust the format of the val split of the dataset to be used with ImageFolder."""

import torch
from torch import nn
from torchvision.datasets import ImageFolder
import torchvision.transforms as T
from tqdm import tqdm
from torch.cuda.amp import autocast, GradScaler

# with open('tiny-imagenet/tiny-imagenet-200/val/val_annotations.txt') as f:
#     for line in f:
#         fn, cls, *_ = line.split('\t')
#         os.makedirs(f'tiny-imagenet/tiny-imagenet-200/val/{cls}', exist_ok=True)
#
#         shutil.copyfile(f'tiny-imagenet/tiny-imagenet-200/val/images/{fn}', f'tiny-imagenet/tiny-imagenet-200/val/{cls}/{fn}')
#
# shutil.rmtree('tiny-imagenet/tiny-imagenet-200/val/images')



transform = T.Compose([
    T.Resize((224, 224)),  # Resize to fit the input dimensions of the network

    # I added these -----------------------------------------------------------------
    T.RandomHorizontalFlip(),
    T.RandomRotation(10),
    T.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # -
    T.RandomPerspective(),
    # -------------------------------------------------------------------------------

    T.ToTensor(),
    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])

# root/{classX}/x001.jpg

tiny_imagenet_dataset_train = ImageFolder(root='tiny-imagenet/tiny-imagenet-200/train', transform=transform)
tiny_imagenet_dataset_val = ImageFolder(root='tiny-imagenet/tiny-imagenet-200/val', transform=transform)

if torch.utils.data.get_worker_info() is None:
    print(f"Length of train dataset: {len(tiny_imagenet_dataset_train)}")
    print(f"Length of val dataset: {len(tiny_imagenet_dataset_val)}")

# The following code also checks the number of samples per class
# from collections import Counter

# class_counts = Counter([target for _, target in tiny_imagenet_dataset_val])
# for class_label, count in class_counts.items():
#     print(f"Class {class_label}: {count} entries")


train_loader = torch.utils.data.DataLoader(tiny_imagenet_dataset_train, batch_size=32, shuffle=True)
val_loader = torch.utils.data.DataLoader(tiny_imagenet_dataset_val, batch_size=32, shuffle=False)

print("Data Loading Complete!")


"""## Custom model definition"""

# Define the custom neural network
class CustomNet(nn.Module):
    def __init__(self, in_channels, out_channels, stride=1):
        super(CustomNet, self).__init__()
        # Define layers of the neural network
        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1, stride=1)
        self.bn1 = nn.BatchNorm2d(64)

        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)
        self.bn2 = nn.BatchNorm2d(128)

        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, padding=1)
        self.bn3 = nn.BatchNorm2d(256)

        self.maxpool2d = nn.MaxPool2d(kernel_size=2, stride=2)
        self.relu = nn.ReLU()

        self.gap = nn.AdaptiveAvgPool2d((1, 1)) # fix feature mismatch using adaptive average global pooling
        self.dropout2d = nn.Dropout2d(p=0.2) # kills entire future maps in a 4d tensor (B, C, H, W)

        self.flatten = nn.Flatten(start_dim=1)
        self.dropout = nn.Dropout(p=0.5)
        self.fc1 = nn.Linear(256, 200) # 200 is the number of classes in TinyImageNet

        # Shortcut connection
        if stride != 1 or in_channels != out_channels:
            self.shortcut = nn.Sequential(
                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride),
                nn.BatchNorm2d(out_channels)
            )
        else:
            self.shortcut = nn.Identity()  # Do nothing if dimensions match

    def forward(self, x):
        # Define forward pass
        # B x 3 x 224 x 224
        x = self.relu(self.bn1(self.conv1(x)))
        x = self.maxpool2d(x) # B x 64 x 112 x 112

        x = self.relu(self.bn2(self.conv2(x)))
        x = self.maxpool2d(x) # B x 128 x 56 x 56

        x = self.relu(self.bn3(self.conv3(x)))
        x = self.maxpool2d(x) # B x 256 x 28 x 28

        x = self.gap(x) # global average pooling
        x = self.flatten(x) # flatten before fully connected layer to correct the dimensions (batch size, 256)

        x = self.dropout(x) # add dropout to avoid overfitting
        x = self.fc1(x)
        return x

scaler = GradScaler()

def train(epoch, model, train_loader, criterion, optimizer, verbose=True):
    model.train()
    running_loss, correct, total = 0.0, 0, 0

    loader = tqdm(train_loader, desc=f"Train Epoch {epoch}", leave=False) if verbose else train_loader

    for batch_idx, (inputs, targets) in enumerate(loader):
        inputs, targets = inputs.cuda(non_blocking=True), targets.cuda(non_blocking=True)

        optimizer.zero_grad()

        # ðŸ”¥ Autocast: use half precision automatically
        with autocast():
            outputs = model(inputs)
            loss = criterion(outputs, targets)

        # ðŸ”¥ Scale the loss and call backward
        scaler.scale(loss).backward()
        scaler.step(optimizer)
        scaler.update()

        running_loss += loss.item()
        _, predicted = outputs.max(1)
        total += targets.size(0)
        correct += predicted.eq(targets).sum().item()

    train_loss = running_loss / len(train_loader)
    train_accuracy = 100. * correct / total
    print(f'Train Epoch: {epoch} Loss: {train_loss:.6f} Acc: {train_accuracy:.2f}%')


# Validation loop
def validate(model, val_loader, criterion, verbose=True):
    model.eval()
    val_loss = 0

    correct, total = 0, 0

    loader = tqdm(val_loader, desc="Validating", leave=False) if verbose else val_loader

    with torch.no_grad():
        for batch_idx, (inputs, targets) in enumerate(loader):
            inputs, targets = inputs.cuda(), targets.cuda()

            outputs = model(inputs)
            loss = criterion(outputs, targets)

            val_loss += loss.item()
            _, predicted = outputs.max(1)
            total += targets.size(0)
            correct += predicted.eq(targets).sum().item()

    val_loss = val_loss / len(val_loader)
    val_accuracy = 100. * correct / total

    print(f'Validation Loss: {val_loss:.6f} Acc: {val_accuracy:.2f}%')
    return val_accuracy

"""## Putting everything together"""


if __name__ == '__main__':
    torch.set_float32_matmul_precision('high')
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"Using device: {device}")
    model = CustomNet()
    model = model.to(device)

    criterion = nn.CrossEntropyLoss()
    optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)

    best_acc = 0

    # Run the training process for {num_epochs} epochs
    num_epochs = 10
    for epoch in range(1, num_epochs + 1):

        train(epoch, model, train_loader, criterion, optimizer)

        # At the end of each training iteration, perform a validation step
        val_accuracy = validate(model, val_loader, criterion)

        # Best validation accuracy
        best_acc = max(best_acc, val_accuracy)

    print(f'Best validation accuracy: {best_acc:.2f}%')